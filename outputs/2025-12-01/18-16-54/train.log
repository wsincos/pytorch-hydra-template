[__main__][INFO] - ====== Configuration ======
[__main__][INFO] - 
train:
  seed: 42
  device: cuda
  epochs: 20
checkpoint:
  enabled: true
  save_dir: checkpoints
model:
  name: seq2seq_transformer
  wrapper:
    name: Seq2SeqWrapper
  shared:
    src_vocab_size: 21128
    tgt_vocab_size: 21128
    d_model: 512
    pe_cfg:
      name: SinusoidalPE
      d_model: 512
      dropout: 0.1
      max_len: 5000
  arch:
    encoder:
      name: TransformerEncoder
      input_dim: 21128
      d_model: 512
      nhead: 8
      num_layers: 6
      pe_cfg:
        name: SinusoidalPE
        d_model: 512
        dropout: 0.1
        max_len: 5000
    decoder:
      name: TransformerDecoder
      output_dim: 21128
      d_model: 512
      nhead: 8
      num_layers: 6
      pe_cfg:
        name: SinusoidalPE
        d_model: 512
        dropout: 0.1
        max_len: 5000
dataset:
  name: Opus100Dataset
  train_path: ./data/datasets/opus-100/train/train-00000-of-00001.parquet
  test_path: ./data/datasets/opus-100/test/test-00000-of-00001.parquet
  source_lang: en
  target_lang: zh
  tokenizer_path: ./data/pretrained_models/bert-base-chinese
  max_samples: -1
  seq_len: 128
  batch_size: 128
  num_workers: 8
optimizer:
  name: AdamW
  params:
    lr: 0.0005
    weight_decay: 0.01
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-08
criterion:
  name: CrossEntropyLoss
  params: {}
logger:
  enable: true
  project: hydra-styple-transformer
  entity: null
  name: full-run-1
  group: null
  tags: []
  notes: null
  mode: online
callback:
  ckpt:
    name: CheckpointCallback
    params:
      save_every: 1
      keep_last: true
  early_stop:
    name: EarlyStopping
    params:
      patience: 3
      min_delta: 0.001
scheduler:
  name: CosineAnnealingLR
  params:
    T_max: 20
    eta_min: 1.0e-06

[__main__][INFO] - ===========================
[__main__][INFO] - Initializing Solver with GPU: 6
[src.solver][INFO] - Building Loader...
[src.data.datasets][INFO] - [Data] Loading local parquet file: ./data/datasets/opus-100/train/train-00000-of-00001.parquet...
[src.data.datasets][INFO] - [Data] Loading Tokenizer from: ./data/pretrained_models/bert-base-chinese...
[src.data.datasets][INFO] - [Data] Loading local parquet file: ./data/datasets/opus-100/test/test-00000-of-00001.parquet...
[src.solver][INFO] - Auto-setting vocab size from Tokenizer: 21128
[src.solver][INFO] - Building Model: seq2seq_transformer
[src.models.builders][INFO] - [Builder] Instantiating Encoder: TransformerEncoder
[src.models.builders][INFO] - [Builder] Instantiating Decoder: TransformerDecoder
[src.models.builders][INFO] - [Builder] Instantiating Model: Seq2SeqWrapper
[src.solver][INFO] - Building Callback: ckpt (CheckpointCallback)
[src.callbacks.checkpoint][INFO] - [Callback] Checkpoints will be saved to: /data1/jinyu_wang/projects/pytorch-hydra/outputs/2025-12-01/18-16-54/checkpoints
[src.solver][INFO] - Building Callback: early_stop (EarlyStopping)
[src.solver][INFO] - Start Training... Total Epochs: 20
[src.solver][INFO] - Epoch 0 | Step 0 | Train Loss: 10.1345
[src.solver][INFO] - === Epoch 0 Done | Train Loss: 6.4467 ===
[src.solver][INFO] - New Best Model! Loss: inf -> 6.4236
[src.callbacks.checkpoint][INFO] - Saved checkpoint: /data1/jinyu_wang/projects/pytorch-hydra/outputs/2025-12-01/18-16-54/checkpoints/checkpoint_epoch_1.pt
[src.callbacks.checkpoint][INFO] - Saved BEST model to /data1/jinyu_wang/projects/pytorch-hydra/outputs/2025-12-01/18-16-54/checkpoints/checkpoint_best.pt
[src.solver][INFO] - LR updated to: 0.00049693
[src.solver][INFO] - Epoch 1 | Step 0 | Train Loss: 6.4286
[src.solver][INFO] - === Epoch 1 Done | Train Loss: 6.4360 ===
[src.callbacks.checkpoint][INFO] - Saved checkpoint: /data1/jinyu_wang/projects/pytorch-hydra/outputs/2025-12-01/18-16-54/checkpoints/checkpoint_epoch_2.pt
[src.solver][INFO] - LR updated to: 0.00048779
[src.solver][INFO] - Epoch 2 | Step 0 | Train Loss: 6.3921
[src.solver][INFO] - === Epoch 2 Done | Train Loss: 6.4345 ===
[src.solver][INFO] - New Best Model! Loss: 6.4236 -> 6.4202
[src.callbacks.checkpoint][INFO] - Saved checkpoint: /data1/jinyu_wang/projects/pytorch-hydra/outputs/2025-12-01/18-16-54/checkpoints/checkpoint_epoch_3.pt
[src.callbacks.checkpoint][INFO] - Saved BEST model to /data1/jinyu_wang/projects/pytorch-hydra/outputs/2025-12-01/18-16-54/checkpoints/checkpoint_best.pt
[src.solver][INFO] - LR updated to: 0.00047281
[src.solver][INFO] - Epoch 3 | Step 0 | Train Loss: 6.4548
[src.solver][INFO] - === Epoch 3 Done | Train Loss: 6.4337 ===
[src.callbacks.checkpoint][INFO] - Saved checkpoint: /data1/jinyu_wang/projects/pytorch-hydra/outputs/2025-12-01/18-16-54/checkpoints/checkpoint_epoch_4.pt
[src.callbacks.early_stopping][INFO] - [EarlyStopping] Counter: 1/3 (Best: 6.4202)
[src.solver][INFO] - LR updated to: 0.00045235
[src.solver][INFO] - Epoch 4 | Step 0 | Train Loss: 6.4703
[src.solver][INFO] - === Epoch 4 Done | Train Loss: 6.4332 ===
[src.callbacks.checkpoint][INFO] - Saved checkpoint: /data1/jinyu_wang/projects/pytorch-hydra/outputs/2025-12-01/18-16-54/checkpoints/checkpoint_epoch_5.pt
[src.solver][INFO] - LR updated to: 0.00042692
[src.solver][INFO] - Epoch 5 | Step 0 | Train Loss: 6.3798
[src.solver][INFO] - === Epoch 5 Done | Train Loss: 6.4329 ===
[src.callbacks.checkpoint][INFO] - Saved checkpoint: /data1/jinyu_wang/projects/pytorch-hydra/outputs/2025-12-01/18-16-54/checkpoints/checkpoint_epoch_6.pt
[src.solver][INFO] - LR updated to: 0.00039715
[src.solver][INFO] - Epoch 6 | Step 0 | Train Loss: 6.5023
[src.solver][INFO] - === Epoch 6 Done | Train Loss: 6.4326 ===
[src.callbacks.checkpoint][INFO] - Saved checkpoint: /data1/jinyu_wang/projects/pytorch-hydra/outputs/2025-12-01/18-16-54/checkpoints/checkpoint_epoch_7.pt
[src.solver][INFO] - LR updated to: 0.00036377
[src.solver][INFO] - Epoch 7 | Step 0 | Train Loss: 6.3617
[asyncio][WARNING] - socket.send() raised exception.
[asyncio][WARNING] - socket.send() raised exception.
[asyncio][WARNING] - socket.send() raised exception.
[asyncio][WARNING] - socket.send() raised exception.
[asyncio][WARNING] - socket.send() raised exception.
[asyncio][WARNING] - socket.send() raised exception.
[asyncio][WARNING] - socket.send() raised exception.
[asyncio][WARNING] - socket.send() raised exception.
[asyncio][WARNING] - socket.send() raised exception.
[asyncio][WARNING] - socket.send() raised exception.
[asyncio][WARNING] - socket.send() raised exception.
[asyncio][WARNING] - socket.send() raised exception.
[asyncio][WARNING] - socket.send() raised exception.
[asyncio][WARNING] - socket.send() raised exception.
