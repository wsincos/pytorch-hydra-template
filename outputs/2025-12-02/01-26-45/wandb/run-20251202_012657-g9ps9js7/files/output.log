[src.solver][INFO] - Start Training... Total Epochs: 3
Error executing job with overrides: ['train.epochs=3', 'dataset.max_samples=500', 'logger.name=test_run_03', 'callback.training_monitor.params.log_every_n_steps=50', 'dataset.batch_size=32']
Traceback (most recent call last):
  File "/data1/jinyu_wang/projects/pytorch-hydra/train.py", line 32, in main
    solver.train()
  File "/data1/jinyu_wang/projects/pytorch-hydra/src/solver.py", line 231, in train
    loss = self.run_step(x, y)
  File "/data1/jinyu_wang/projects/pytorch-hydra/src/solver.py", line 191, in run_step
    loss.backward()
  File "/data1/jinyu_wang/miniconda3/envs/transformer/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/data1/jinyu_wang/miniconda3/envs/transformer/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.81 GiB (GPU 0; 23.70 GiB total capacity; 8.90 GiB already allocated; 160.81 MiB free; 9.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
