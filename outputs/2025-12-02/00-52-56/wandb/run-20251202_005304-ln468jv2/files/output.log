[src.solver][INFO] - Start Training... Total Epochs: 3
[src.solver][INFO] - === Epoch 0 Done | Train Loss: 8.0785 ===
[src.callbacks.checkpoint][INFO] - New Best Model! Loss: inf -> 7.0368
[src.callbacks.checkpoint][INFO] - Saved BEST model to /data1/jinyu_wang/projects/pytorch-hydra/outputs/2025-12-02/00-52-56/checkpoints/checkpoint_best.pt
[src.callbacks.generation_monitor][INFO] - --- [Translation Demo] ---
Error executing job with overrides: ['train.epochs=3', 'dataset.max_samples=500', 'logger.name=test_run_01', 'callback.training_monitor.params.log_every_n_steps=50', 'dataset.batch_size=32']
Traceback (most recent call last):
  File "/data1/jinyu_wang/projects/pytorch-hydra/train.py", line 32, in main
    solver.train()
  File "/data1/jinyu_wang/projects/pytorch-hydra/src/solver.py", line 263, in train
    self.trigger_callbacks("on_epoch_end")
  File "/data1/jinyu_wang/projects/pytorch-hydra/src/solver.py", line 129, in trigger_callbacks
    getattr(cb, hook_name)(self)
  File "/data1/jinyu_wang/projects/pytorch-hydra/src/callbacks/generation_monitor.py", line 51, in on_epoch_end
    pred_texts = solver.inference(src_texts)
  File "/data1/jinyu_wang/miniconda3/envs/transformer/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/data1/jinyu_wang/projects/pytorch-hydra/src/solver.py", line 177, in inference
    decoded_preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)
  File "/data1/jinyu_wang/miniconda3/envs/transformer/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 4019, in batch_decode
    return [
  File "/data1/jinyu_wang/miniconda3/envs/transformer/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 4020, in <listcomp>
    self.decode(
  File "/data1/jinyu_wang/miniconda3/envs/transformer/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 4059, in decode
    return self._decode(
  File "/data1/jinyu_wang/miniconda3/envs/transformer/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 682, in _decode
    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)
TypeError: argument 'ids': 'Tensor' object cannot be converted to 'Sequence'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
