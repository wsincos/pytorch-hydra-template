[src.solver][INFO] - Start Training... Total Epochs: 3
[src.solver][INFO] - === Epoch 0 Done | Train Loss: 8.0785 ===
[src.callbacks.checkpoint][INFO] - New Best Model! Loss: inf -> 7.0368
[src.callbacks.checkpoint][INFO] - Saved BEST model to /data1/jinyu_wang/projects/pytorch-hydra/outputs/2025-12-02/00-49-25/checkpoints/checkpoint_best.pt
[src.callbacks.generation_monitor][INFO] - --- [Translation Demo] ---
Error executing job with overrides: ['train.epochs=3', 'dataset.max_samples=500', 'logger.name=test_run_01', 'callback.training_monitor.params.log_every_n_steps=50', 'dataset.batch_size=32']
Traceback (most recent call last):
  File "/data1/jinyu_wang/projects/pytorch-hydra/train.py", line 32, in main
    solver.train()
  File "/data1/jinyu_wang/projects/pytorch-hydra/src/solver.py", line 264, in train
    self.trigger_callbacks("on_epoch_end")
  File "/data1/jinyu_wang/projects/pytorch-hydra/src/solver.py", line 129, in trigger_callbacks
    getattr(cb, hook_name)(self)
  File "/data1/jinyu_wang/projects/pytorch-hydra/src/callbacks/generation_monitor.py", line 51, in on_epoch_end
    pred_texts = solver.inference(src_texts)
  File "/data1/jinyu_wang/miniconda3/envs/transformer/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/data1/jinyu_wang/projects/pytorch-hydra/src/solver.py", line 157, in inference
    inputs = tokenizer(
  File "/data1/jinyu_wang/miniconda3/envs/transformer/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 3073, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/data1/jinyu_wang/miniconda3/envs/transformer/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 3161, in _call_one
    return self.batch_encode_plus(
  File "/data1/jinyu_wang/miniconda3/envs/transformer/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 3362, in batch_encode_plus
    return self._batch_encode_plus(
  File "/data1/jinyu_wang/miniconda3/envs/transformer/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 601, in _batch_encode_plus
    return BatchEncoding(sanitized_tokens, sanitized_encodings, tensor_type=return_tensors)
  File "/data1/jinyu_wang/miniconda3/envs/transformer/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 249, in __init__
    self.convert_to_tensors(tensor_type=tensor_type, prepend_batch_axis=prepend_batch_axis)
  File "/data1/jinyu_wang/miniconda3/envs/transformer/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 735, in convert_to_tensors
    raise ImportError("Unable to convert output to PyTorch tensors format, PyTorch is not installed.")
ImportError: Unable to convert output to PyTorch tensors format, PyTorch is not installed.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
